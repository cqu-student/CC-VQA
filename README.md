# CC-VQA: Conflict- and Correlation-Aware Method for Mitigating Knowledge Conflict in Knowledge-Based Visual Question Answering
[![arXiv](https://img.shields.io/badge/arXiv-2602.14605-b31b1b.svg)](https://arxiv.org/abs/)
[![CVPR 2025](https://img.shields.io/badge/CVPR%202026-Poster-red)]([https://icml.cc/](https://neurips.cc/))
[![Python](https://img.shields.io/badge/Python-3.10+-blue)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.16+-orange)](https://pytorch.org/)

This repository provides the official PyTorch implementation for CC-VQA.

## ðŸªµ TODO List

- ðŸ”„ Complete README documentation
- ðŸ”„ Release core train implementation
- ðŸ”„ Add configuration examples
- ðŸ”„ Add More detailed Quick Start.

## ðŸ”¥ What's New

- **(2026.2.20)** The dataset setting can be found in echosight (https://github.com/Go2Heart/EchoSight)
- **(2026.2.20)** ðŸŽ‰ Our paper (CC-VQA) is accepted as **CVPR 2026**!

## ðŸš€ Get Started

```bash
git clone https://github.com/cqu-student/CC-VQA.git
cd CC-VQA
pip install -r requirements.txt
